import SwiftUI
import AppKit

struct MainEditorView: View {
    @StateObject var viewModel = AudioPlayerViewModel()
    @StateObject var analysisVM = AudioAnalysisViewModel()
    @StateObject var audioProcessor = AudioProcessor()
    @StateObject var dynamicVolumeVM = DynamicVolumeBalanceViewModel()
    @State private var isWaveformHovered: Bool = false
    @State private var showAnalysisWindow = false
    @State private var currentFileURL: URL?

    // åˆ†æžå®Œæˆæç¤º
    @State private var showAnalysisCompleted = false
    @State private var analysisCompletedTimer: Timer?

    var body: some View {
        // åˆå§‹åŒ–æ—¶è®¾ç½® audioEngine å¼•ç”¨ï¼ˆä»…åœ¨é¦–æ¬¡ä¸ºnilæ—¶è®¾ç½®ï¼‰
        if dynamicVolumeVM.audioEngine == nil {
            dynamicVolumeVM.audioEngine = viewModel.audioEngine
        }

        return ZStack(alignment: .bottom) {
            VStack(spacing: 0) {
                HStack(spacing: 8) {
                    // æ’­æ”¾/æš‚åœæŒ‰é’®
                    Button(action: {
                        viewModel.togglePlayPause()
                    }) {
                        Image(systemName: viewModel.isPlaying ? "pause.fill" : "play.fill")
                            .font(.system(size: 16, weight: .semibold))
                            .frame(width: 32, height: 32)
                    }
                    .keyboardShortcut(.space, modifiers: [])
                    .help(viewModel.isPlaying ? "æš‚åœ" : "æ’­æ”¾")

                    // é‡æ–°å¼€å§‹æŒ‰é’®
                    Button(action: {
                        viewModel.seekToBeginning()
                    }) {
                        Image(systemName: "backward.end.fill")
                            .font(.system(size: 16, weight: .semibold))
                            .frame(width: 32, height: 32)
                    }
                    .help("é‡æ–°å¼€å§‹")

                    // åˆ†æžæŒ‰é’®
                    Button(action: {
                        if analysisVM.isCurrentFileAnalyzed {
                            // å·²åˆ†æž - æ‰“å¼€åˆ†æžç»“æžœçª—å£
                            AnalysisWindowManager.shared.show(analysisVM: analysisVM)
                        } else if let url = currentFileURL {
                            // æœªåˆ†æž - å¼€å§‹åˆ†æž
                            analysisVM.analyzeAudioFile(url: url)
                        }
                    }) {
                        Image(systemName: "waveform.circle")
                            .font(.system(size: 16, weight: .semibold))
                            .frame(width: 32, height: 32)
                    }
                    .disabled(currentFileURL == nil || analysisVM.isAnalyzing)
                    .help(analysisVM.isCurrentFileAnalyzed ? "æŸ¥çœ‹åˆ†æžç»“æžœ" : "åˆ†æžéŸ³é¢‘")

                    Spacer()

                    // æ—¶é—´æ˜¾ç¤º
                    HStack(spacing: 2) {
                        Text(timeString(viewModel.currentTime))
                            .font(.system(size: 12, design: .monospaced))
                        Text("/")
                            .foregroundStyle(.secondary)
                            .font(.system(size: 12, design: .monospaced))
                        Text(timeString(viewModel.duration))
                            .font(.system(size: 12, design: .monospaced))
                            .foregroundStyle(.secondary)

                        // ç¼©æ”¾çº§åˆ«æ˜¾ç¤º
                        if viewModel.waveformScale > 1.0 {
                            Text("  ")
                            Text("ç¼©æ”¾: \(Int(viewModel.waveformScale * 100))%")
                                .font(.system(size: 11, design: .monospaced))
                                .foregroundStyle(.secondary)
                        }
                    }

                    Spacer()

                    // åŠ¨æ€éŸ³é‡å¹³è¡¡æŒ‰é’®
                    Button(action: {
                        if dynamicVolumeVM.envelopeData == nil && !analysisVM.features.isEmpty {
                            // å·²æœ‰åˆ†æžç»“æžœï¼Œç›´æŽ¥ç”Ÿæˆå¢žç›ŠåŒ…ç»œ
                            // ä½¿ç”¨ç‰¹å¾æ•°æ®æœ¬èº«çš„æ—¶é—´èŒƒå›´ï¼ˆç¡®ä¿æ—¶é—´æ˜ å°„ä¸€è‡´ï¼‰
                            dynamicVolumeVM.calculateGainEnvelope(from: analysisVM.features)
                        } else if analysisVM.features.isEmpty && currentFileURL != nil {
                            // æ²¡æœ‰åˆ†æžç»“æžœï¼Œå…ˆåˆ†æž
                            analysisVM.analyzeAudioFile(url: currentFileURL!)
                        }
                    }) {
                        Image(systemName: dynamicVolumeVM.isEnabled ? "waveform.badge.magnifyingglass.fill" : "waveform.badge.magnifyingglass")
                            .font(.system(size: 16, weight: .semibold))
                            .frame(width: 32, height: 32)
                    }
                    .disabled(currentFileURL == nil)
                    .help(dynamicVolumeVM.isEnabled ? "åŠ¨æ€éŸ³é‡å¹³è¡¡å·²å¯ç”¨" : "å¯ç”¨åŠ¨æ€éŸ³é‡å¹³è¡¡")

                    // å¯¼å‡ºæŒ‰é’® - çº¯å›¾æ ‡æ ·å¼
                    Button(action: exportProcessedAudio) {
                        Image(systemName: "square.and.arrow.up")
                            .font(.system(size: 16, weight: .semibold))
                            .frame(width: 32, height: 32)
                    }
                    .disabled(currentFileURL == nil || analysisVM.features.isEmpty)
                    .help("å¯¼å‡ºå¤„ç†åŽçš„éŸ³é¢‘")
                }
                .padding(8)

                Divider()

                TimelineRuler(currentTime: viewModel.currentTime, duration: viewModel.duration, scale: viewModel.waveformScale, scrollOffset: viewModel.waveformScrollOffset, waveformWidth: viewModel.waveformWidth)
                    .frame(height: 28)

                ZStack(alignment: .topTrailing) {
                    WaveformView(viewModel: viewModel, isHovered: $isWaveformHovered)
                        .background(Color(NSColor.controlBackgroundColor))

                    // Toast æç¤º - ä½¿ç”¨ overlay ä¸å ç”¨ç©ºé—´
                    if analysisVM.isAnalyzing {
                        // åˆ†æžè¿›åº¦ä¸­ Toast
                        VStack(spacing: 8) {
                            ProgressView(value: analysisVM.analysisProgress)
                                .frame(width: 150)
                            HStack(spacing: 6) {
                                Text("åˆ†æžä¸­...")
                                    .font(.caption)
                                Text("\(Int(analysisVM.analysisProgress * 100))%")
                                    .font(.caption)
                                    .foregroundStyle(.secondary)
                            }
                        }
                        .padding(12)
                        .background(Color.black.opacity(0.7))
                        .foregroundColor(.white)
                        .cornerRadius(8)
                        .padding(.top, 12)
                        .padding(.trailing, 20)
                        .transition(.move(edge: .top).combined(with: .opacity))
                    } else if showAnalysisCompleted {
                        // åˆ†æžå®Œæˆæç¤º Toast
                        Text("âœ“ åˆ†æžå®Œæˆ")
                            .font(.system(size: 14, weight: .medium))
                            .foregroundColor(.white)
                            .padding(.horizontal, 16)
                            .padding(.vertical, 8)
                            .background(
                                RoundedRectangle(cornerRadius: 8)
                                    .fill(Color.green.opacity(0.8))
                            )
                            .padding(.top, 12)
                            .padding(.trailing, 20)
                            .transition(.move(edge: .top).combined(with: .opacity))
                    } else if viewModel.showToast {
                        ToastView(message: viewModel.toastMessage)
                            .padding(.top, 12)
                            .padding(.trailing, 20)
                            .transition(.move(edge: .top).combined(with: .opacity))
                    }
                }

                Divider()

                // å¢žç›ŠåŒ…ç»œæ›²çº¿ - ä¸Žæ³¢å½¢å®Œå…¨ç»‘å®š
                if dynamicVolumeVM.isEnabled {
                    VStack(spacing: 0) {
                        Text("å¢žç›ŠåŒ…ç»œ")
                            .font(.caption2)
                            .foregroundStyle(.secondary)
                            .padding(.vertical, 4)

                        GainEnvelopeCurveView(
                            envelopeData: dynamicVolumeVM.envelopeData,
                            currentTime: viewModel.currentTime,
                            duration: viewModel.duration,
                            scrollOffset: viewModel.waveformScrollOffset,
                            scale: viewModel.waveformScale,
                            waveformWidth: viewModel.waveformWidth
                        )
                    }
                    .frame(height: 60)
                }

                // AU æ•ˆæžœå™¨é“¾é¢æ¿
                EffectSlotsPanel(audioEngine: viewModel.audioEngine)
                    .frame(height: 150)
            }

            // æ»šåŠ¨æ¡ - åœ¨æ•ˆæžœå™¨é“¾é¢æ¿ä¸Šæ–¹
            if viewModel.isWaveformScrollable {
                HorizontalScrollbar(viewModel: viewModel)
                    .frame(height: 12)
                    .offset(y: -150) // å‘ä¸Šåç§»æ•ˆæžœå™¨é“¾é¢æ¿çš„é«˜åº¦
            }
        }
        .ignoresSafeArea(.all, edges: .bottom)
        .background(DropViewRepresentable(onDropped: handleDroppedFiles))
        .onReceive(viewModel.$currentTime) { currentTime in
            if viewModel.isPlaying && viewModel.waveformScale > 1.0 {
                viewModel.updatePlaybackFollow()
            }

            // å¦‚æžœå¯ç”¨äº†åŠ¨æ€éŸ³é‡å¹³è¡¡ï¼Œåº”ç”¨å¢žç›Š
            if dynamicVolumeVM.isEnabled, let gain = dynamicVolumeVM.getGainAtTime(currentTime) {
                viewModel.audioEngine.applyDynamicGain(gain)
            }
        }
        .onReceive(viewModel.$isPlaying) { isPlaying in
            if !isPlaying {
                viewModel.resetPlaybackFollow()
            }
        }
        .background(EventHandlingView(viewModel: viewModel, isWaveformHovered: isWaveformHovered))
        .onReceive(NotificationCenter.default.publisher(for: NSNotification.Name("didImportAudioFile"))) { notification in
            if let url = notification.userInfo?["url"] as? URL {
                currentFileURL = url
                // æ›´æ–°analysisVMçš„å½“å‰æ–‡ä»¶URL
                analysisVM.currentFileURL = url
                // åˆ‡æ¢æ–‡ä»¶æ—¶é‡ç½®åˆ†æžå®Œæˆæ ‡è®°
                showAnalysisCompleted = false
            }
        }
        .onReceive(analysisVM.$isAnalyzing) { isAnalyzing in
            if !isAnalyzing && analysisVM.analysisProgress >= 1.0 {
                // åˆ†æžå®Œæˆ - æ˜¾ç¤ºå®Œæˆæç¤º2ç§’
                showAnalysisCompleted = true

                // å–æ¶ˆä¹‹å‰çš„è®¡æ—¶å™¨
                analysisCompletedTimer?.invalidate()

                // è®¾ç½®2ç§’åŽéšè—
                analysisCompletedTimer = Timer.scheduledTimer(withTimeInterval: 2.0, repeats: false) { _ in
                    withAnimation {
                        showAnalysisCompleted = false
                    }
                }
            }
        }
    }

    // å¤„ç†æ‹–æ‹½æ‰“å¼€æ–‡ä»¶
    private func handleDroppedFiles(_ url: URL) {
        currentFileURL = url
        analysisVM.currentFileURL = url
        showAnalysisCompleted = false
    }

    private func timeString(_ t: Double) -> String {
        guard t.isFinite else { return "00:00" }
        let total = Int(t.rounded())
        let s = total % 60
        let m = (total / 60) % 60
        let h = total / 3600
        if h > 0 {
            return String(format: "%02d:%02d:%02d", h, m, s)
        } else {
            return String(format: "%02d:%02d", m, s)
        }
    }

    // å¯¼å‡ºå¤„ç†åŽçš„éŸ³é¢‘
    private func exportProcessedAudio() {
        guard let inputURL = currentFileURL else { return }
        guard !analysisVM.features.isEmpty else { return }

        let savePanel = NSSavePanel()
        savePanel.allowedContentTypes = [.audio]
        savePanel.canCreateDirectories = true
        savePanel.isExtensionHidden = false
        savePanel.title = "å¯¼å‡ºå¤„ç†åŽçš„éŸ³é¢‘"
        savePanel.nameFieldStringValue = "processed_\(inputURL.deletingPathExtension().lastPathComponent).m4a"

        savePanel.begin { response in
            if response == .OK, let outputURL = savePanel.url {
                Task {
                    await processAndExport(inputURL: inputURL, outputURL: outputURL)
                }
            }
        }
    }

    private func processAndExport(inputURL: URL, outputURL: URL) async {
        do {
            // ä¼˜å…ˆä½¿ç”¨åŠ¨æ€éŸ³é‡å¹³è¡¡ç”Ÿæˆçš„å¢žç›ŠåŒ…ç»œ
            let gains: [Float]
            if dynamicVolumeVM.isEnabled, let envelopeData = dynamicVolumeVM.envelopeData {
                gains = envelopeData.gains
                print("ðŸ“Š ä½¿ç”¨åŠ¨æ€å¢žç›ŠåŒ…ç»œè¿›è¡Œå¯¼å‡º: \(gains.count)ä¸ªå¢žç›Šç‚¹")
            } else {
                // é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŽŸå§‹çš„éŸ³é‡å¹³è¡¡å¢žç›Šè®¡ç®—
                gains = audioProcessor.calculateVolumeGains(features: analysisVM.features)
                print("ðŸ“Š ä½¿ç”¨åŽŸå§‹å¢žç›Šè®¡ç®—è¿›è¡Œå¯¼å‡º: \(gains.count)ä¸ªå¢žç›Šç‚¹")
            }

            try await audioProcessor.processAudioFile(
                inputURL: inputURL,
                outputURL: outputURL,
                gains: gains,
                hopSize: 768,
                frameSize: 1024
            ) { progress in
                // å¯¼å‡ºè¿›åº¦å›žè°ƒ
            }
            viewModel.showToast(message: "âœ“ å¯¼å‡ºæˆåŠŸï¼")
        } catch {
            print("âŒ å¯¼å‡ºå¤±è´¥: \(error.localizedDescription)")
        }
    }
}

// æ¨ªå‘æ»šåŠ¨æ¡ï¼ˆå‚è€ƒ Miniwaveï¼‰
struct HorizontalScrollbar: View {
    @ObservedObject var viewModel: AudioPlayerViewModel
    
    @State private var isDragging = false
    @State private var dragStartX: CGFloat = 0
    @State private var dragStartOffset: CGFloat = 0
    
    var body: some View {
        GeometryReader { geometry in
            ZStack(alignment: .leading) {
                Rectangle()
                    .fill(Color.secondary.opacity(0.1))
                    .frame(height: 4)
                    .cornerRadius(2)
                
                Rectangle()
                    .fill(isDragging ? Color.accentColor : Color.secondary.opacity(0.3))
                    .frame(width: thumbWidth(geometry: geometry), height: 6)
                    .cornerRadius(3)
                    .offset(x: thumbOffset(geometry: geometry))
                    .gesture(
                        DragGesture()
                            .onChanged { value in
                                if !isDragging {
                                    isDragging = true
                                    viewModel.isScrollbarDragging = true
                                    dragStartX = value.startLocation.x
                                    dragStartOffset = thumbOffset(geometry: geometry)
                                }
                                updateScrollOffset(dragLocation: value.location.x, geometry: geometry)
                            }
                            .onEnded { _ in
                                isDragging = false
                                viewModel.isScrollbarDragging = false
                            }
                    )
            }
        }
        .ignoresSafeArea(.container, edges: .bottom)
    }
    
    private func thumbWidth(geometry: GeometryProxy) -> CGFloat {
        let availableWidth = geometry.size.width
        let scale = viewModel.waveformScale
        let thumbWidth = availableWidth / scale
        return max(20, thumbWidth)
    }
    
    private func thumbOffset(geometry: GeometryProxy) -> CGFloat {
        let availableWidth = geometry.size.width
        let thumbWidth = thumbWidth(geometry: geometry)
        let maxOffset = availableWidth - thumbWidth
        
        guard maxOffset > 0 else { return 0 }
        
        let visibleWidth = viewModel.waveformWidth
        let totalScaledWidth = visibleWidth * viewModel.waveformScale
        let maxScrollOffset = max(0, totalScaledWidth - visibleWidth)
        
        guard maxScrollOffset > 0 else { return 0 }
        
        let scrollRatio = viewModel.waveformScrollOffset / maxScrollOffset
        return scrollRatio * maxOffset
    }
    
    private func updateScrollOffset(dragLocation: CGFloat, geometry: GeometryProxy) {
        let availableWidth = geometry.size.width
        let thumbWidth = thumbWidth(geometry: geometry)
        let maxOffset = availableWidth - thumbWidth
        
        guard maxOffset > 0 else { return }
        
        let visibleWidth = viewModel.waveformWidth
        let totalScaledWidth = visibleWidth * viewModel.waveformScale
        let maxScrollOffset = max(0, totalScaledWidth - visibleWidth)
        
        guard maxScrollOffset > 0 else { return }
        
        let dragDistance = dragLocation - dragStartX
        let newOffset = max(0, min(maxOffset, dragStartOffset + dragDistance))
        let offsetRatio = newOffset / maxOffset
        let newScrollOffset = offsetRatio * maxScrollOffset
        
        viewModel.setWaveformScrollOffset(newScrollOffset)
    }
}

// Toast æç¤ºè§†å›¾
struct ToastView: View {
    let message: String
    
    var body: some View {
        Text(message)
            .font(.system(size: 14, weight: .medium))
            .foregroundColor(.white)
            .padding(.horizontal, 16)
            .padding(.vertical, 8)
            .background(
                RoundedRectangle(cornerRadius: 8)
                    .fill(Color.black.opacity(0.7))
            )
    }
}

// äº‹ä»¶å¤„ç†è§†å›¾ï¼ˆå‚è€ƒ Miniwave EventManagerï¼‰
struct EventHandlingView: NSViewRepresentable {
    let viewModel: AudioPlayerViewModel
    let isWaveformHovered: Bool
    
    func makeNSView(context: Context) -> NSView {
        let view = EventCapturingView()
        view.viewModel = viewModel
        view.isWaveformHovered = isWaveformHovered
        return view
    }
    
    func updateNSView(_ nsView: NSView, context: Context) {
        if let eventView = nsView as? EventCapturingView {
            eventView.isWaveformHovered = isWaveformHovered
        }
    }
}

class EventCapturingView: NSView {
    var viewModel: AudioPlayerViewModel?
    var isWaveformHovered: Bool = false
    private var localScrollMonitor: Any?
    private var localMagnifyMonitor: Any?

    override func viewDidMoveToWindow() {
        super.viewDidMoveToWindow()
        startMonitoring()
    }

    deinit {
        stopMonitoring()
    }

    private func startMonitoring() {
        stopMonitoring()
        // æ»šè½®äº‹ä»¶
        localScrollMonitor = NSEvent.addLocalMonitorForEvents(matching: [.scrollWheel]) { [weak self] event in
            guard let self = self,
                  let vm = self.viewModel,
                  self.isWaveformHovered,
                  vm.hasAudioFile else { return event }

            let deltaX = event.scrollingDeltaX
            let deltaY = event.scrollingDeltaY
            let isPrecise = event.hasPreciseScrollingDeltas

            let mouseInView = self.convert(event.locationInWindow, from: nil)
            let mouseX = mouseInView.x
            let waveformWidth = vm.waveformWidth

            if isPrecise {
                if abs(deltaX) > abs(deltaY) * 1.05 {
                    vm.scrollWaveform(delta: -deltaX)
                    return nil
                } else if abs(deltaY) > abs(deltaX) * 1.05 {
                    struct Accumulator { static var y: CGFloat = 0 }
                    Accumulator.y += deltaY
                    if abs(Accumulator.y) >= 4 {
                        let zoomDelta: CGFloat = Accumulator.y < 0 ? 1 : -1
                        vm.zoomWaveformAtPoint(delta: zoomDelta, mouseX: mouseX, waveformWidth: waveformWidth)
                        Accumulator.y = 0
                    }
                    return nil
                }
                return nil
            } else {
                let zoomDelta: CGFloat = deltaY > 0 ? -1.0 : 1.0
                vm.zoomWaveformAtPoint(delta: zoomDelta, mouseX: mouseX, waveformWidth: waveformWidth)
                return nil
            }
        }

        // æåˆäº‹ä»¶
        localMagnifyMonitor = NSEvent.addLocalMonitorForEvents(matching: [.magnify]) { [weak self] event in
            guard let self = self,
                  let vm = self.viewModel,
                  vm.hasAudioFile else { return event }

            struct PinchAccumulator { static var value: CGFloat = 0 }
            PinchAccumulator.value += event.magnification
            if abs(PinchAccumulator.value) >= 0.04 {
                let delta: CGFloat = PinchAccumulator.value > 0 ? 1 : -1
                let mouseInView = self.convert(event.locationInWindow, from: nil)
                let mouseX = mouseInView.x
                vm.zoomWaveformAtPoint(delta: delta, mouseX: mouseX, waveformWidth: vm.waveformWidth)
                PinchAccumulator.value = 0
            }
            return nil
        }
    }

    private func stopMonitoring() {
        if let monitor = localScrollMonitor { NSEvent.removeMonitor(monitor) }
        if let monitor = localMagnifyMonitor { NSEvent.removeMonitor(monitor) }
        localScrollMonitor = nil
        localMagnifyMonitor = nil
    }
}

// æ‹–æ‹½å¤„ç†è§†å›¾ - ä½¿ç”¨åŽŸç”Ÿ NSView å®žçŽ°é¿å… SwiftUI onDrop çš„ IPC é—®é¢˜
struct DropViewRepresentable: NSViewRepresentable {
    let onDropped: (URL) -> Void

    func makeNSView(context: Context) -> DropView {
        let view = DropView()
        view.onDropped = onDropped
        return view
    }

    func updateNSView(_ nsView: DropView, context: Context) {}
}

class DropView: NSView {
    var onDropped: ((URL) -> Void)?

    override func awakeFromNib() {
        super.awakeFromNib()
        registerForDraggedTypes([NSPasteboard.PasteboardType.fileURL])
    }

    override func viewDidMoveToWindow() {
        super.viewDidMoveToWindow()
        registerForDraggedTypes([NSPasteboard.PasteboardType.fileURL])
    }

    override func draggingEntered(_ sender: NSDraggingInfo) -> NSDragOperation {
        let pasteboard = sender.draggingPasteboard
        if pasteboard.types?.contains(NSPasteboard.PasteboardType.fileURL) ?? false {
            return .copy
        }
        return []
    }

    override func performDragOperation(_ sender: NSDraggingInfo) -> Bool {
        let pasteboard = sender.draggingPasteboard

        // å°è¯•èŽ·å–æ–‡ä»¶URL
        if let files = pasteboard.propertyList(forType: NSPasteboard.PasteboardType.fileURL) as? [String] {
            for fileString in files {
                if let url = URL(string: fileString) {
                    if isAudioFile(url) {
                        onDropped?(url)
                        return true
                    }
                }
            }
        }

        // å¤‡é€‰æ–¹æ¡ˆï¼šç›´æŽ¥ä»Ž pasteboard çš„ URLs å±žæ€§èŽ·å–
        if let urls = pasteboard.readObjects(forClasses: [NSURL.self], options: nil) as? [URL] {
            if let url = urls.first, isAudioFile(url) {
                onDropped?(url)
                return true
            }
        }

        return false
    }

    private func isAudioFile(_ url: URL) -> Bool {
        let audioExtensions = ["m4a", "mp3", "wav", "aac", "flac", "aiff"]
        let fileExtension = url.pathExtension.lowercased()
        return audioExtensions.contains(fileExtension)
    }
}

