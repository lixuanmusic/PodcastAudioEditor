import SwiftUI

struct AudioAnalysisWindow: View {
    let result: AudioAnalysisResult
    @State private var selectedTab: String = "overview"
    
    var body: some View {
        VStack(spacing: 0) {
            // æ ‡é¢˜æ 
            HStack {
                Text("ðŸŽµ éŸ³é¢‘åˆ†æžç»“æžœ")
                    .font(.headline)
                Spacer()
                Button("å…³é—­") {
                    NSApplication.shared.keyWindow?.close()
                }
            }
            .padding()
            .background(Color.gray.opacity(0.1))
            
            // æ ‡ç­¾é¡µ
            Picker("åˆ†æžç±»åž‹", selection: $selectedTab) {
                Text("æ¦‚è§ˆ").tag("overview")
                Text("é™éŸ³æ®µ").tag("silences")
                Text("å“åº¦å˜åŒ–").tag("loudness")
                Text("éŸ³ä¹/å‘è¨€").tag("speech_music")
                Text("å‘è¨€äºº").tag("speakers")
            }
            .pickerStyle(.segmented)
            .padding()
            
            // å†…å®¹åŒº
            TabView(selection: $selectedTab) {
                OverviewTab(result: result)
                    .tag("overview")
                
                SilencesTab(silences: result.silences ?? [])
                    .tag("silences")
                
                LoudnessTab(segments: result.loudness_segments ?? [])
                    .tag("loudness")
                
                SpeechMusicTab(segments: result.speech_music ?? [])
                    .tag("speech_music")
                
                SpeakersTab(speakers: result.speaker_changes ?? [])
                    .tag("speakers")
            }
            
            Spacer()
        }
        .frame(minWidth: 600, minHeight: 500)
    }
}

// MARK: - æ¦‚è§ˆé€‰é¡¹å¡
struct OverviewTab: View {
    let result: AudioAnalysisResult
    
    var body: some View {
        ScrollView {
            VStack(alignment: .leading, spacing: 16) {
                // åŸºæœ¬ä¿¡æ¯
                GroupBox(label: Label("åŸºæœ¬ä¿¡æ¯", systemImage: "info.circle")) {
                    VStack(alignment: .leading, spacing: 8) {
                        HStack {
                            Text("æ€»æ—¶é•¿:")
                            Spacer()
                            Text(formatTime(result.duration ?? 0))
                        }
                        HStack {
                            Text("é‡‡æ ·çŽ‡:")
                            Spacer()
                            Text("\(result.sample_rate ?? 0) Hz")
                        }
                    }
                }
                
                // åˆ†æžç»Ÿè®¡
                if let silences = result.silences {
                    GroupBox(label: Label("é™éŸ³æ®µ", systemImage: "speaker.slash")) {
                        VStack(alignment: .leading, spacing: 4) {
                            Text("æ•°é‡: \(silences.count)")
                            if !silences.isEmpty {
                                let totalDuration = silences.reduce(0) { $0 + $1.duration }
                                Text("æ€»æ—¶é•¿: \(formatTime(totalDuration))")
                            }
                        }
                    }
                }
                
                if let loudness = result.loudness_segments {
                    GroupBox(label: Label("å“åº¦å˜åŒ–", systemImage: "waveform")) {
                        Text("æ£€æµ‹åˆ° \(loudness.count) å¤„å“åº¦å˜åŒ–")
                    }
                }
                
                if let speechMusic = result.speech_music {
                    GroupBox(label: Label("å†…å®¹åˆ†ç±»", systemImage: "music.note")) {
                        VStack(alignment: .leading, spacing: 4) {
                            let speechCount = speechMusic.filter { $0.type == "speech" }.count
                            let musicCount = speechMusic.filter { $0.type == "music" }.count
                            Text("å‘è¨€: \(speechCount) æ®µ")
                            Text("éŸ³ä¹: \(musicCount) æ®µ")
                        }
                    }
                }
                
                if let speakers = result.speaker_changes {
                    GroupBox(label: Label("å‘è¨€äººå˜åŒ–", systemImage: "person.2")) {
                        Text("æ£€æµ‹åˆ° \(speakers.count) æ¬¡å˜åŒ–")
                    }
                }
                
                Spacer()
            }
            .padding()
        }
    }
}

// MARK: - é™éŸ³æ®µé€‰é¡¹å¡
struct SilencesTab: View {
    let silences: [Silence]
    
    var body: some View {
        List(silences, id: \.start) { silence in
            VStack(alignment: .leading, spacing: 4) {
                HStack {
                    Text("ðŸ“")
                    Text("\(formatTime(silence.start)) - \(formatTime(silence.end))")
                        .font(.caption)
                    Spacer()
                    Text(formatTime(silence.duration))
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
            }
        }
        .listStyle(.plain)
    }
}

// MARK: - å“åº¦å˜åŒ–é€‰é¡¹å¡
struct LoudnessTab: View {
    let segments: [LoudnessChange]
    
    var body: some View {
        List(segments, id: \.time) { segment in
            VStack(alignment: .leading, spacing: 4) {
                HStack {
                    Text("ðŸ“Š")
                    Text(formatTime(segment.time))
                        .font(.caption)
                    Spacer()
                    Text(String(format: "%.2f", segment.magnitude))
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
            }
        }
        .listStyle(.plain)
    }
}

// MARK: - éŸ³ä¹/å‘è¨€é€‰é¡¹å¡
struct SpeechMusicTab: View {
    let segments: [SpeechMusicSegment]
    
    var body: some View {
        List(segments, id: \.start) { segment in
            VStack(alignment: .leading, spacing: 4) {
                HStack {
                    Text(segment.type == "speech" ? "ðŸŽ¤" : "ðŸŽµ")
                    Text("\(formatTime(segment.start)) - \(formatTime(segment.end))")
                        .font(.caption)
                    Spacer()
                    Text(segment.type)
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
            }
        }
        .listStyle(.plain)
    }
}

// MARK: - å‘è¨€äººé€‰é¡¹å¡
struct SpeakersTab: View {
    let speakers: [SpeakerChange]
    
    var body: some View {
        List(speakers, id: \.time) { speaker in
            VStack(alignment: .leading, spacing: 4) {
                HStack {
                    Text("ðŸ‘¤")
                    Text(formatTime(speaker.time))
                        .font(.caption)
                    Spacer()
                    Text(String(format: "%.2f", speaker.distance))
                        .font(.caption)
                        .foregroundColor(.secondary)
                }
            }
        }
        .listStyle(.plain)
    }
}

// MARK: - è¾…åŠ©å‡½æ•°
func formatTime(_ seconds: Double) -> String {
    let minutes = Int(seconds) / 60
    let secs = Int(seconds) % 60
    let ms = Int((seconds.truncatingRemainder(dividingBy: 1)) * 1000)
    return String(format: "%02d:%02d.%03d", minutes, secs, ms)
}

#Preview {
    AudioAnalysisWindow(result: AudioAnalysisResult(
        success: true,
        error: nil,
        duration: 180,
        sample_rate: 22050,
        silences: [
            Silence(type: "silence", start: 0, end: 0.5, duration: 0.5),
            Silence(type: "silence", start: 30, end: 31, duration: 1)
        ],
        loudness_segments: [
            LoudnessChange(type: "loudness_change", time: 15, magnitude: 0.5)
        ],
        speech_music: [
            SpeechMusicSegment(type: "speech", start: 0, end: 90, confidence: 0.9),
            SpeechMusicSegment(type: "music", start: 90, end: 180, confidence: 0.8)
        ],
        speaker_changes: [
            SpeakerChange(type: "speaker_change", time: 45, distance: 2.5)
        ],
        segments: []
    ))
}
