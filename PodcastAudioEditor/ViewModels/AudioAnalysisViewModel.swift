import SwiftUI
import Combine

class AudioAnalysisViewModel: ObservableObject {
    @Published var features: [AcousticFeatures] = []
    @Published var segments: [Segment] = []
    @Published var isAnalyzing = false
    @Published var analysisProgress: Double = 0.0
    @Published var showAnalysisWindow = false
    
    // æå–å™¨é€‰æ‹©å’Œæ€§èƒ½å¯¹æ¯”
    @Published var selectedExtractor: FeatureExtractorType = .accelerate
    @Published var comparePerformance: Bool = false
    @Published var accelerateMetrics: PerformanceMetrics?
    @Published var audioKitMetrics: PerformanceMetrics?
    @Published var performanceComparison: String = ""
    
    private var featureExtractor: FeatureExtractorProtocol?
    private var segmentDetector: SegmentDetector?
    
    // æ€§èƒ½å¯¹æ¯”æ—¶ä¸´æ—¶ä¿å­˜æå–å™¨
    private var accelerateExtractorForComparison: AccelerateFeatureExtractor?
    private var audioKitExtractorForComparison: AudioKitFeatureExtractor?
    
    // ç»Ÿè®¡ä¿¡æ¯
    @Published var totalSilenceDuration: Double = 0.0
    @Published var totalSpeechDuration: Double = 0.0
    @Published var totalMusicDuration: Double = 0.0
    @Published var averageEnergy: Float = 0.0
    @Published var averageZCR: Float = 0.0
    
    // åˆ†æéŸ³é¢‘æ–‡ä»¶
    func analyzeAudioFile(url: URL) {
        if comparePerformance {
            // æ€§èƒ½å¯¹æ¯”æ¨¡å¼ï¼šä¸¤ç§æ–¹æ¡ˆéƒ½è¿è¡Œ
            performComparison(url: url)
        } else {
            // å•æ–¹æ¡ˆæ¨¡å¼
            analyzeWithExtractor(url: url, type: selectedExtractor)
        }
    }
    
    // ä½¿ç”¨æŒ‡å®šæå–å™¨åˆ†æ
    private func analyzeWithExtractor(url: URL, type: FeatureExtractorType) {
        let extractor: FeatureExtractorProtocol?
        
        switch type {
        case .accelerate:
            extractor = AccelerateFeatureExtractor(audioFileURL: url)
        case .audioKit:
            extractor = AudioKitFeatureExtractor(audioFileURL: url)
        }
        
        guard let extractor = extractor else {
            print("âŒ æ— æ³•åˆ›å»ºç‰¹å¾æå–å™¨: \(type.description)")
            return
        }
        
        self.featureExtractor = extractor
        isAnalyzing = true
        analysisProgress = 0.0
        
        extractor.extractFeaturesAsync(
            onProgress: { [weak self] progress in
                self?.analysisProgress = progress * 0.7  // å‰70%ç”¨äºç‰¹å¾æå–
            },
            completion: { [weak self] in
                self?.onFeaturesExtracted(features: extractor.features, metrics: extractor.performanceMetrics)
            }
        )
    }
    
    // æ€§èƒ½å¯¹æ¯”æ¨¡å¼
    private func performComparison(url: URL) {
        isAnalyzing = true
        analysisProgress = 0.0
        accelerateMetrics = nil
        audioKitMetrics = nil
        
        print("ğŸ“Š å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
        print(String(repeating: "=", count: 50))
        
        // å…ˆè¿è¡Œ Accelerate
        print("\nğŸ”µ æµ‹è¯• Accelerate æ–¹æ¡ˆ...")
        guard let accelerateExtractor = AccelerateFeatureExtractor(audioFileURL: url) else {
            print("âŒ æ— æ³•åˆ›å»º Accelerate æå–å™¨")
            return
        }
        
        self.accelerateExtractorForComparison = accelerateExtractor
        let accelerateStart = CFAbsoluteTimeGetCurrent()
        accelerateExtractor.extractFeaturesAsync(
            onProgress: { [weak self] progress in
                DispatchQueue.main.async {
                    // å‰50%è¿›åº¦ç”¨äº Accelerate
                    self?.analysisProgress = progress * 0.5
                }
            },
            completion: { [weak self] in
                let accelerateTime = CFAbsoluteTimeGetCurrent() - accelerateStart
                DispatchQueue.main.async {
                    self?.accelerateMetrics = accelerateExtractor.performanceMetrics
                    print("âœ… Accelerate å®Œæˆï¼Œè€—æ—¶: \(String(format: "%.3f", accelerateTime))ç§’")
                    
                    // ç„¶åè¿è¡Œ AudioKit
                    self?.runAudioKitExtractor(url: url, accelerateTime: accelerateTime)
                }
            }
        )
    }
    
    // è¿è¡Œ AudioKit æå–å™¨ï¼ˆåœ¨æ€§èƒ½å¯¹æ¯”æ¨¡å¼ä¸­ï¼‰
    private func runAudioKitExtractor(url: URL, accelerateTime: TimeInterval) {
        print("\nğŸŸ¢ æµ‹è¯• AudioKit æ–¹æ¡ˆ...")
        guard let audioKitExtractor = AudioKitFeatureExtractor(audioFileURL: url) else {
            print("âŒ æ— æ³•åˆ›å»º AudioKit æå–å™¨")
            return
        }
        
        self.audioKitExtractorForComparison = audioKitExtractor
        let audioKitStart = CFAbsoluteTimeGetCurrent()
        audioKitExtractor.extractFeaturesAsync(
            onProgress: { [weak self] progress in
                DispatchQueue.main.async {
                    // å50%è¿›åº¦ç”¨äº AudioKit (0.5 + progress * 0.5)
                    self?.analysisProgress = 0.5 + progress * 0.5
                }
            },
            completion: { [weak self] in
                let audioKitTime = CFAbsoluteTimeGetCurrent() - audioKitStart
                DispatchQueue.main.async {
                    self?.audioKitMetrics = audioKitExtractor.performanceMetrics
                    print("âœ… AudioKit å®Œæˆï¼Œè€—æ—¶: \(String(format: "%.3f", audioKitTime))ç§’")
                    
                    // ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
                    self?.generateComparisonReport(accelerateTime: accelerateTime, audioKitTime: audioKitTime)
                    
                    // ä½¿ç”¨é€‰ä¸­çš„æå–å™¨çš„ç»“æœ
                    guard let accelerateExtractor = self?.accelerateExtractorForComparison else { return }
                    let finalExtractor: FeatureExtractorProtocol = self?.selectedExtractor == .accelerate ? accelerateExtractor : audioKitExtractor
                    self?.featureExtractor = finalExtractor
                    self?.onFeaturesExtracted(features: finalExtractor.features, metrics: finalExtractor.performanceMetrics)
                }
            }
        )
    }
    
    // ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
    private func generateComparisonReport(accelerateTime: TimeInterval, audioKitTime: TimeInterval) {
        guard let accMetrics = accelerateMetrics,
              let akMetrics = audioKitMetrics else { return }
        
        let faster = accelerateTime < audioKitTime ? "Accelerate" : "AudioKit"
        let speedup = max(accelerateTime, audioKitTime) / min(accelerateTime, audioKitTime)
        let percentDiff = abs(accelerateTime - audioKitTime) / min(accelerateTime, audioKitTime) * 100
        
        var report = """
        ğŸ“Š æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
        ========================================
        
        æ€»è€—æ—¶å¯¹æ¯”:
        - Accelerate: \(String(format: "%.3f", accelerateTime))ç§’
        - AudioKit:   \(String(format: "%.3f", audioKitTime))ç§’
        - æ›´å¿«æ–¹æ¡ˆ:   \(faster)
        - åŠ é€Ÿæ¯”:     \(String(format: "%.2f", speedup))x
        - æ€§èƒ½å·®å¼‚:   \(String(format: "%.1f", percentDiff))%
        
        """
        
        // è¯¦ç»†ç‰¹å¾å¯¹æ¯”
        report += "\nå„ç‰¹å¾è€—æ—¶å¯¹æ¯”:\n"
        report += String(format: "%-20s %12s %12s %10s\n", "ç‰¹å¾", "Accelerate", "AudioKit", "å·®å¼‚")
        report += String(repeating: "-", count: 56) + "\n"
        
        if accMetrics.energyTime > 0 || akMetrics.energyTime > 0 {
            let diff = abs(accMetrics.energyTime - akMetrics.energyTime) / min(accMetrics.energyTime, akMetrics.energyTime) * 100
            report += String(format: "%-20s %10.3fs %10.3fs %9.1f%%\n", "èƒ½é‡", accMetrics.energyTime, akMetrics.energyTime, diff)
        }
        
        if accMetrics.zcrTime > 0 || akMetrics.zcrTime > 0 {
            let diff = abs(accMetrics.zcrTime - akMetrics.zcrTime) / max(min(accMetrics.zcrTime, akMetrics.zcrTime), 0.001) * 100
            report += String(format: "%-20s %10.3fs %10.3fs %9.1f%%\n", "é›¶äº¤å‰ç‡", accMetrics.zcrTime, akMetrics.zcrTime, diff)
        }
        
        if accMetrics.spectralCentroidTime > 0 || akMetrics.spectralCentroidTime > 0 {
            let diff = abs(accMetrics.spectralCentroidTime - akMetrics.spectralCentroidTime) / max(min(accMetrics.spectralCentroidTime, akMetrics.spectralCentroidTime), 0.001) * 100
            report += String(format: "%-20s %10.3fs %10.3fs %9.1f%%\n", "è°±è´¨å¿ƒ", accMetrics.spectralCentroidTime, akMetrics.spectralCentroidTime, diff)
        }
        
        if accMetrics.fftTime > 0 || akMetrics.fftTime > 0 {
            let diff = abs(accMetrics.fftTime - akMetrics.fftTime) / min(accMetrics.fftTime, akMetrics.fftTime) * 100
            report += String(format: "%-20s %10.3fs %10.3fs %9.1f%%\n", "FFT", accMetrics.fftTime, akMetrics.fftTime, diff)
        }
        
        if accMetrics.mfccTime > 0 || akMetrics.mfccTime > 0 {
            let diff = abs(accMetrics.mfccTime - akMetrics.mfccTime) / min(accMetrics.mfccTime, akMetrics.mfccTime) * 100
            report += String(format: "%-20s %10.3fs %10.3fs %9.1f%%\n", "MFCC", accMetrics.mfccTime, akMetrics.mfccTime, diff)
        }
        
        report += "\n" + String(repeating: "=", count: 50)
        
        print(report)
        performanceComparison = report
        
        // åŒæ—¶åœ¨æ§åˆ¶å°è¾“å‡º Accelerate å’Œ AudioKit çš„è¯¦ç»†æŠ¥å‘Š
        print("\nğŸ”µ Accelerate è¯¦ç»†æŠ¥å‘Š:")
        print(accMetrics.report)
        print("\nğŸŸ¢ AudioKit è¯¦ç»†æŠ¥å‘Š:")
        print(akMetrics.report)
    }
    
    // ç‰¹å¾æå–å®Œæˆ
    private func onFeaturesExtracted(features: [AcousticFeatures], metrics: PerformanceMetrics? = nil) {
        self.features = features
        analysisProgress = 0.7
        
        // æ‰§è¡Œæ®µè½æ£€æµ‹
        let detector = SegmentDetector(features: features)
        detector.detectSegments()
        self.segmentDetector = detector
        self.segments = detector.segments
        
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        updateStatistics()
        
        analysisProgress = 1.0
        isAnalyzing = false
        showAnalysisWindow = true
        
        print("âœ“ åˆ†æå®Œæˆ: \(features.count)ä¸ªéŸ³é¢‘å¸§, \(segments.count)ä¸ªæ®µè½")
    }
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    private func updateStatistics() {
        totalSilenceDuration = segments
            .filter { $0.type == .silence }
            .reduce(0) { $0 + $1.duration }
        
        totalSpeechDuration = segments
            .filter { $0.type == .speech }
            .reduce(0) { $0 + $1.duration }
        
        totalMusicDuration = segments
            .filter { $0.type == .music }
            .reduce(0) { $0 + $1.duration }
        
        if !features.isEmpty {
            averageEnergy = features.map { $0.energy }.reduce(0, +) / Float(features.count)
            averageZCR = features.map { $0.zcr }.reduce(0, +) / Float(features.count)
        }
    }
}
