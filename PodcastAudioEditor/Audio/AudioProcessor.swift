import AVFoundation
import Accelerate

// éŸ³é¢‘å¤„ç†é…ç½®
struct AudioProcessingConfig {
    var volumeBalanceEnabled: Bool = false
    var targetLUFS: Float = -16.0  // ç›®æ ‡å“åº¦ï¼ˆLUFSï¼‰
    var maxGainDB: Float = 12.0    // æœ€å¤§å¢ç›Šï¼ˆdBï¼‰
    var minGainDB: Float = -12.0   // æœ€å°å¢ç›Šï¼ˆdBï¼‰
    var smoothingWindow: Int = 100 // å¹³æ»‘çª—å£ï¼ˆå¸§æ•°ï¼‰
}

// éŸ³é¢‘å¤„ç†å™¨ï¼šè´Ÿè´£å„ç§éŸ³é¢‘ä¼˜åŒ–å¤„ç†
class AudioProcessor: ObservableObject {
    @Published var config = AudioProcessingConfig()
    @Published var isProcessing = false
    
    // æ ¹æ®å£°å­¦ç‰¹å¾è®¡ç®—éŸ³é‡è°ƒèŠ‚å¢ç›Š
    func calculateVolumeGains(features: [AcousticFeatures]) -> [Float] {
        guard !features.isEmpty else { return [] }
        
        var gains: [Float] = []
        gains.reserveCapacity(features.count)
        
        // è®¡ç®—æ¯å¸§çš„ç›®æ ‡å¢ç›Š
        for feature in features {
            let gain: Float
            
            // é™éŸ³æ®µä¿æŒåŸæ ·
            if !feature.isVoiced {
                gain = 0.0
            } else {
                // å°†èƒ½é‡ï¼ˆdBï¼‰è½¬æ¢ä¸ºå¢ç›Š
                // ç›®æ ‡ï¼šä½¿å“åº¦æ¥è¿‘ -16 LUFS
                // ç®€åŒ–ï¼šå‡è®¾èƒ½é‡ dB ä¸ LUFS æˆæ­£æ¯”å…³ç³»
                let currentLoudness = feature.energy
                let targetLoudness = config.targetLUFS
                
                // è®¡ç®—éœ€è¦çš„å¢ç›Š
                var calculatedGain = targetLoudness - currentLoudness
                
                // é™åˆ¶åœ¨èŒƒå›´å†…
                calculatedGain = max(config.minGainDB, min(config.maxGainDB, calculatedGain))
                
                gain = calculatedGain
            }
            
            gains.append(gain)
        }
        
        // å¹³æ»‘å¢ç›Šæ›²çº¿ï¼ˆé¿å…çªå˜ï¼‰
        let smoothedGains = smoothGains(gains, windowSize: config.smoothingWindow)
        
        return smoothedGains
    }
    
    // å¹³æ»‘å¢ç›Šæ›²çº¿
    private func smoothGains(_ gains: [Float], windowSize: Int) -> [Float] {
        guard gains.count > windowSize else { return gains }
        
        var smoothed: [Float] = []
        smoothed.reserveCapacity(gains.count)
        
        let halfWindow = windowSize / 2
        
        for i in 0..<gains.count {
            let startIdx = max(0, i - halfWindow)
            let endIdx = min(gains.count, i + halfWindow + 1)
            
            var sum: Float = 0
            var count: Float = 0
            
            for j in startIdx..<endIdx {
                sum += gains[j]
                count += 1
            }
            
            smoothed.append(sum / count)
        }
        
        return smoothed
    }
    
    // åº”ç”¨éŸ³é‡è°ƒèŠ‚åˆ°éŸ³é¢‘æ–‡ä»¶
    func processAudioFile(
        inputURL: URL,
        outputURL: URL,
        gains: [Float],
        hopSize: Int = 768,
        frameSize: Int = 1024,
        onProgress: @escaping (Double) -> Void
    ) async throws {
        guard let audioFile = try? AVAudioFile(forReading: inputURL) else {
            throw NSError(domain: "AudioProcessor", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶"])
        }
        
        let format = audioFile.processingFormat
        let totalFrames = Int(audioFile.length)
        
        // åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        guard let outputFile = try? AVAudioFile(
            forWriting: outputURL,
            settings: format.settings,
            commonFormat: format.commonFormat,
            interleaved: format.isInterleaved
        ) else {
            throw NSError(domain: "AudioProcessor", code: -2, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶"])
        }
        
        // è¯»å–æ•´ä¸ªéŸ³é¢‘æ–‡ä»¶
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(totalFrames)) else {
            throw NSError(domain: "AudioProcessor", code: -3, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•åˆ›å»ºç¼“å†²åŒº"])
        }
        
        try audioFile.read(into: buffer)
        
        guard let channelData = buffer.floatChannelData else {
            throw NSError(domain: "AudioProcessor", code: -4, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è·å–éŸ³é¢‘æ•°æ®"])
        }
        
        let channelCount = Int(format.channelCount)
        let sampleCount = Int(buffer.frameLength)
        
        print("ğŸ“Š å¼€å§‹å¤„ç†éŸ³é¢‘: \(sampleCount)é‡‡æ ·ç‚¹, \(channelCount)å£°é“")
        
        // åº”ç”¨å¢ç›Šåˆ°æ¯ä¸ªé‡‡æ ·ç‚¹
        for channel in 0..<channelCount {
            let samples = channelData[channel]
            
            for sampleIdx in 0..<sampleCount {
                // è®¡ç®—å¯¹åº”çš„å¸§ç´¢å¼•
                let frameIdx = sampleIdx / hopSize
                let gainIdx = min(frameIdx, gains.count - 1)
                
                // è·å–å¢ç›Šï¼ˆdBè½¬çº¿æ€§ï¼‰
                let gainDB = gains[gainIdx]
                let gainLinear = pow(10.0, gainDB / 20.0)
                
                // åº”ç”¨å¢ç›Š
                samples[sampleIdx] *= gainLinear
                
                // é˜²æ­¢å‰Šæ³¢ï¼ˆé™åˆ¶åœ¨ -1.0 åˆ° 1.0ï¼‰
                samples[sampleIdx] = max(-1.0, min(1.0, samples[sampleIdx]))
                
                // è¿›åº¦æ›´æ–°
                if channel == 0 && sampleIdx % 100000 == 0 {
                    let progress = Double(sampleIdx) / Double(sampleCount)
                    onProgress(progress)
                }
            }
        }
        
        // å†™å…¥è¾“å‡ºæ–‡ä»¶
        try outputFile.write(from: buffer)
        
        onProgress(1.0)
        print("âœ“ éŸ³é¢‘å¤„ç†å®Œæˆ")
    }
}

